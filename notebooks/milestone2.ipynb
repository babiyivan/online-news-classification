{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including pandas, torch, os, tqdm, conllu, sklearn, and transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import tqdm\n",
    "from conllu import parse\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import hamming_loss, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Map Labels\n",
    "Define a function to load and map labels from a given file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'narratives': ['URW: Discrediting the West, Diplomacy', 'URW: Amplifying war-related fears', 'URW: Amplifying war-related fears'], 'subnarratives': ['URW: Discrediting the West, Diplomacy: West is tired of Ukraine', 'URW: Amplifying war-related fears: NATO should/will directly intervene', 'URW: Amplifying war-related fears: By continuing the war we risk WWIII']}\n"
     ]
    }
   ],
   "source": [
    "def load_and_map_labels(label_file_path):\n",
    "    labels_df = pd.read_csv(label_file_path, sep=\"\\t\", header=None, names=[\"article_id\", \"narratives\", \"subnarratives\"])\n",
    "    \n",
    "    labels_mapping = {\n",
    "        row[\"article_id\"]: {\n",
    "            \"narratives\": row[\"narratives\"].split(\";\"),\n",
    "            \"subnarratives\": row[\"subnarratives\"].split(\";\")\n",
    "        }\n",
    "        for _, row in labels_df.iterrows()\n",
    "    }\n",
    "    \n",
    "    return labels_mapping\n",
    "\n",
    "label_file = \"../data/training_data_16_October_release/EN/subtask-2-annotations.txt\"\n",
    "labels_mapping = load_and_map_labels(label_file)\n",
    "print(labels_mapping[\"EN_UA_015443.txt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse and Load Articles\n",
    "Define functions to parse CoNLL-U files and load articles from a given path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_conllu_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "    token_lists = parse(data)\n",
    "    all_tokens = [token[\"form\"] for token_list in token_lists for token in token_list]\n",
    "    return \" \".join(all_tokens)\n",
    "\n",
    "def load_articles_from_conllu(articles_path, article_ids, labels_mapping):\n",
    "    articles_data = []\n",
    "    for article_id in article_ids:\n",
    "        file_path = os.path.join(articles_path, f\"{article_id.replace('.txt', '.conllu')}\")\n",
    "        if os.path.exists(file_path):\n",
    "            article_text = parse_conllu_file(file_path)\n",
    "            labels = labels_mapping.get(article_id, {\"narratives\": [], \"subnarratives\": []})\n",
    "            articles_data.append({\n",
    "                \"article_id\": article_id,\n",
    "                \"text\": article_text,\n",
    "                \"narratives\": labels[\"narratives\"],\n",
    "                \"subnarratives\": labels[\"subnarratives\"]\n",
    "            })\n",
    "    return articles_data\n",
    "\n",
    "articles_path = \"../data/tmp/EN\"\n",
    "article_ids = labels_mapping.keys()\n",
    "articles_data = load_articles_from_conllu(articles_path, article_ids, labels_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Tokenizer\n",
    "Initialize the RoBERTa tokenizer using the 'roberta-base' model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d63d899f4d4ba0a5419f8f1c6e045b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ahmed\\.cache\\huggingface\\hub\\models--roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd4594d758346d486df41dc30651648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85188b5f6e7641e5b83ef723d367ee33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0116450d8d7a49799d2c43b90cc73bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df2253a3baa4374aa8ef1d6a9770b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "tokenized_data = [tokenize_function(article) for article in articles_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize Data\n",
    "Define a function to tokenize the data using the RoBERTa tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "tokenized_data = [tokenize_function(article) for article in articles_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Label Vocabulary\n",
    "Generate label vocabularies for narratives and subnarratives and create encoding functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_narratives = sorted({n for article in articles_data for n in article[\"narratives\"]})\n",
    "all_subnarratives = sorted({sn for article in articles_data for sn in article[\"subnarratives\"]})\n",
    "\n",
    "narrative_to_index = {n: i for i, n in enumerate(all_narratives)}\n",
    "subnarrative_to_index = {sn: i for i, sn in enumerate(all_subnarratives)}\n",
    "\n",
    "def encode_labels(narratives, subnarratives):\n",
    "    narrative_vector = [0] * len(all_narratives)\n",
    "    subnarrative_vector = [0] * len(all_subnarratives)\n",
    "\n",
    "    for n in narratives:\n",
    "        narrative_vector[narrative_to_index[n]] = 1\n",
    "    for sn in subnarratives:\n",
    "        subnarrative_vector[subnarrative_to_index[sn]] = 1\n",
    "\n",
    "    return narrative_vector + subnarrative_vector\n",
    "\n",
    "for article in articles_data:\n",
    "    article[\"labels\"] = encode_labels(article[\"narratives\"], article[\"subnarratives\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Labels\n",
    "Encode the labels for each article using the generated vocabularies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_labels(narratives, subnarratives):\n",
    "    narrative_vector = [0] * len(all_narratives)\n",
    "    subnarrative_vector = [0] * len(all_subnarratives)\n",
    "\n",
    "    for n in narratives:\n",
    "        narrative_vector[narrative_to_index[n]] = 1\n",
    "    for sn in subnarratives:\n",
    "        subnarrative_vector[subnarrative_to_index[sn]] = 1\n",
    "\n",
    "    return narrative_vector + subnarrative_vector\n",
    "\n",
    "for article in articles_data:\n",
    "    article[\"labels\"] = encode_labels(article[\"narratives\"], article[\"subnarratives\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset Class\n",
    "Define a custom Dataset class to handle the tokenized data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NarrativeDataset(Dataset):\n",
    "    def __init__(self, articles):\n",
    "        self.articles = articles\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.articles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        article = self.articles[idx]\n",
    "        inputs = tokenizer(\n",
    "            article[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        labels = torch.tensor(article[\"labels\"], dtype=torch.float)\n",
    "        return {**inputs, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model\n",
    "Initialize the RoBERTa model for sequence classification with the appropriate number of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57f54b2c903421fa6c211c63533f5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=92, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_labels = len(all_narratives) + len(all_subnarratives)\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\", \n",
    "    num_labels=num_labels\n",
    ")\n",
    "model = model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Validation Split\n",
    "Split the data into training and validation sets and create DataLoader instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data, val_data = train_test_split(articles_data, test_size=0.2, random_state=42)\n",
    "train_dataset = NarrativeDataset(train_data)\n",
    "val_dataset = NarrativeDataset(val_data)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=6, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=6, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop\n",
    "Define and execute the training loop, including the optimizer and loss calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 27/27 [05:38<00:00, 12.54s/it, Batch Loss=0.3569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed.\n",
      "- Average Loss: 0.3757\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 27/27 [05:07<00:00, 11.39s/it, Batch Loss=0.2439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed.\n",
      "- Average Loss: 0.2817\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 27/27 [04:43<00:00, 10.50s/it, Batch Loss=0.2757]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed.\n",
      "- Average Loss: 0.2243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs): \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm.tqdm(train_loader, desc=\"Processing Batches\", leave=True)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs = {key: val.squeeze(1).to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"Batch Loss\": f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1} completed.\")\n",
    "    print(f\"- Average Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Define a function to evaluate the model on the validation set and print the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on Validation Set...\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                                                                                                            precision    recall  f1-score   support\n",
      "\n",
      "                                                                          CC: Climate change is beneficial       0.00      0.00      0.00         1\n",
      "                                                                  CC: Controversy about green technologies       0.00      0.00      0.00         3\n",
      "                                                                         CC: Criticism of climate movement       0.00      0.00      0.00         4\n",
      "                                                                         CC: Criticism of climate policies       0.00      0.00      0.00         4\n",
      "                                                             CC: Criticism of institutions and authorities       0.00      0.00      0.00         5\n",
      "                                                                            CC: Downplaying climate change       0.00      0.00      0.00         1\n",
      "                                                           CC: Green policies are geopolitical instruments       0.00      0.00      0.00         1\n",
      "                                                     CC: Hidden plots by secret schemes of powerful groups       0.00      0.00      0.00         1\n",
      "                                                              CC: Questioning the measurements and science       0.00      0.00      0.00         1\n",
      "                                                                                                     Other       0.45      1.00      0.62        18\n",
      "                                                                         URW: Amplifying war-related fears       0.00      0.00      0.00         7\n",
      "                                                    URW: Blaming the war on others rather than the invader       0.00      0.00      0.00         8\n",
      "                                                                                 URW: Discrediting Ukraine       0.00      0.00      0.00         4\n",
      "                                                                     URW: Discrediting the West, Diplomacy       0.00      0.00      0.00         7\n",
      "                                                                               URW: Distrust towards Media       0.00      0.00      0.00         1\n",
      "                                                    URW: Hidden plots by secret schemes of powerful groups       0.00      0.00      0.00         1\n",
      "                                                                   URW: Negative Consequences for the West       0.00      0.00      0.00         0\n",
      "                                                                                URW: Overpraising the West       0.00      0.00      0.00         1\n",
      "                                                                                     URW: Praise of Russia       0.00      0.00      0.00         2\n",
      "                                                                                 URW: Russia is the Victim       0.00      0.00      0.00         3\n",
      "                                                                             URW: Speculating war outcomes       0.00      0.00      0.00         2\n",
      "                                                       CC: Climate change is beneficial: CO2 is beneficial       0.00      0.00      0.00         1\n",
      "                                                           CC: Controversy about green technologies: Other       0.00      0.00      0.00         2\n",
      "                                      CC: Controversy about green technologies: Renewable energy is costly       0.00      0.00      0.00         1\n",
      "                                   CC: Controversy about green technologies: Renewable energy is dangerous       0.00      0.00      0.00         1\n",
      "                                  CC: Controversy about green technologies: Renewable energy is unreliable       0.00      0.00      0.00         1\n",
      "                                    CC: Criticism of climate movement: Ad hominem attacks on key activists       0.00      0.00      0.00         3\n",
      "                                           CC: Criticism of climate movement: Climate movement is alarmist       0.00      0.00      0.00         1\n",
      "                                            CC: Criticism of climate movement: Climate movement is corrupt       0.00      0.00      0.00         2\n",
      "                                                                  CC: Criticism of climate movement: Other       0.00      0.00      0.00         0\n",
      "                                       CC: Criticism of climate policies: Climate policies are ineffective       0.00      0.00      0.00         2\n",
      "                                   CC: Criticism of climate policies: Climate policies are only for profit       0.00      0.00      0.00         0\n",
      "                   CC: Criticism of climate policies: Climate policies have negative impact on the economy       0.00      0.00      0.00         2\n",
      "                                                                  CC: Criticism of climate policies: Other       0.00      0.00      0.00         3\n",
      "                        CC: Criticism of institutions and authorities: Criticism of international entities       0.00      0.00      0.00         0\n",
      "                          CC: Criticism of institutions and authorities: Criticism of national governments       0.00      0.00      0.00         2\n",
      "           CC: Criticism of institutions and authorities: Criticism of political organizations and figures       0.00      0.00      0.00         4\n",
      "                                        CC: Criticism of institutions and authorities: Criticism of the EU       0.00      0.00      0.00         0\n",
      "                                                      CC: Criticism of institutions and authorities: Other       0.00      0.00      0.00         0\n",
      "                        CC: Downplaying climate change: CO2 concentrations are too small to have an impact       0.00      0.00      0.00         1\n",
      "                                                CC: Downplaying climate change: Climate cycles are natural       0.00      0.00      0.00         0\n",
      "                                                        CC: Downplaying climate change: Ice is not melting       0.00      0.00      0.00         0\n",
      "           CC: Green policies are geopolitical instruments: Green activities are a form of neo-colonialism       0.00      0.00      0.00         1\n",
      "                              CC: Hidden plots by secret schemes of powerful groups: Blaming global elites       0.00      0.00      0.00         1\n",
      "                  CC: Hidden plots by secret schemes of powerful groups: Climate agenda has hidden motives       0.00      0.00      0.00         0\n",
      "                                              CC: Hidden plots by secret schemes of powerful groups: Other       0.00      0.00      0.00         0\n",
      "CC: Questioning the measurements and science: Greenhouse effect/carbon dioxide do not drive climate change       0.00      0.00      0.00         0\n",
      "            CC: Questioning the measurements and science: Methodologies/metrics used are unreliable/faulty       0.00      0.00      0.00         0\n",
      "                                                       CC: Questioning the measurements and science: Other       0.00      0.00      0.00         0\n",
      "                          CC: Questioning the measurements and science: Scientific community is unreliable       0.00      0.00      0.00         1\n",
      "                                                                                                     Other       0.00      0.00      0.00        18\n",
      "                                    URW: Amplifying war-related fears: By continuing the war we risk WWIII       0.00      0.00      0.00         3\n",
      "                                    URW: Amplifying war-related fears: NATO should/will directly intervene       0.00      0.00      0.00         0\n",
      "                                                                  URW: Amplifying war-related fears: Other       0.00      0.00      0.00         2\n",
      "                                URW: Amplifying war-related fears: Russia will also attack other countries       0.00      0.00      0.00         3\n",
      "      URW: Amplifying war-related fears: There is a real possibility that nuclear weapons will be employed       0.00      0.00      0.00         2\n",
      "                       URW: Blaming the war on others rather than the invader: The West are the aggressors       0.00      0.00      0.00         8\n",
      "                          URW: Blaming the war on others rather than the invader: Ukraine is the aggressor       0.00      0.00      0.00         0\n",
      "                   URW: Discrediting Ukraine: Discrediting Ukrainian government and officials and policies       0.00      0.00      0.00         0\n",
      "                                                URW: Discrediting Ukraine: Discrediting Ukrainian military       0.00      0.00      0.00         0\n",
      "                                               URW: Discrediting Ukraine: Situation in Ukraine is hopeless       0.00      0.00      0.00         1\n",
      "                                       URW: Discrediting Ukraine: Ukraine is a hub for criminal activities       0.00      0.00      0.00         0\n",
      "                                                URW: Discrediting Ukraine: Ukraine is a puppet of the West       0.00      0.00      0.00         3\n",
      "                                              URW: Discrediting Ukraine: Ukraine is associated with nazism       0.00      0.00      0.00         1\n",
      "                                       URW: Discrediting the West, Diplomacy: Diplomacy does/will not work       0.00      0.00      0.00         1\n",
      "                                                              URW: Discrediting the West, Diplomacy: Other       0.00      0.00      0.00         4\n",
      "                                                  URW: Discrediting the West, Diplomacy: The EU is divided       0.00      0.00      0.00         1\n",
      "     URW: Discrediting the West, Diplomacy: The West does not care about Ukraine, only about its interests       0.00      0.00      0.00         2\n",
      "                                           URW: Discrediting the West, Diplomacy: The West is overreacting       0.00      0.00      0.00         0\n",
      "                                                   URW: Discrediting the West, Diplomacy: The West is weak       0.00      0.00      0.00         1\n",
      "                                           URW: Discrediting the West, Diplomacy: West is tired of Ukraine       0.00      0.00      0.00         1\n",
      "                                            URW: Distrust towards Media: Ukrainian media cannot be trusted       0.00      0.00      0.00         0\n",
      "                                 URW: Distrust towards Media: Western media is an instrument of propaganda       0.00      0.00      0.00         1\n",
      "                                             URW: Hidden plots by secret schemes of powerful groups: Other       0.00      0.00      0.00         1\n",
      "                                                            URW: Negative Consequences for the West: Other       0.00      0.00      0.00         0\n",
      "             URW: Negative Consequences for the West: Sanctions imposed by Western countries will backfire       0.00      0.00      0.00         0\n",
      " URW: Negative Consequences for the West: The conflict will increase the Ukrainian refugee flows to Europe       0.00      0.00      0.00         0\n",
      "                                 URW: Overpraising the West: The West belongs in the right side of history       0.00      0.00      0.00         1\n",
      "                              URW: Overpraising the West: The West has the strongest international support       0.00      0.00      0.00         0\n",
      "                                                                              URW: Praise of Russia: Other       0.00      0.00      0.00         0\n",
      "                                         URW: Praise of Russia: Praise of Russian President Vladimir Putin       0.00      0.00      0.00         0\n",
      "                                                   URW: Praise of Russia: Praise of Russian military might       0.00      0.00      0.00         1\n",
      "             URW: Praise of Russia: Russia has international support from a number of countries and people       0.00      0.00      0.00         0\n",
      "                                      URW: Praise of Russia: Russia is a guarantor of peace and prosperity       0.00      0.00      0.00         0\n",
      "                                       URW: Praise of Russia: Russian invasion has strong national support       0.00      0.00      0.00         1\n",
      "                                                                          URW: Russia is the Victim: Other       0.00      0.00      0.00         0\n",
      "                                URW: Russia is the Victim: Russia actions in Ukraine are only self-defence       0.00      0.00      0.00         1\n",
      "                                                        URW: Russia is the Victim: The West is russophobic       0.00      0.00      0.00         2\n",
      "                                                       URW: Russia is the Victim: UA is anti-RU extremists       0.00      0.00      0.00         2\n",
      "                                                                      URW: Speculating war outcomes: Other       0.00      0.00      0.00         1\n",
      "                                                 URW: Speculating war outcomes: Russian army is collapsing       0.00      0.00      0.00         0\n",
      "                                               URW: Speculating war outcomes: Ukrainian army is collapsing       0.00      0.00      0.00         2\n",
      "\n",
      "                                                                                                 micro avg       0.45      0.11      0.17       168\n",
      "                                                                                                 macro avg       0.00      0.01      0.01       168\n",
      "                                                                                              weighted avg       0.05      0.11      0.07       168\n",
      "                                                                                               samples avg       0.45      0.23      0.30       168\n",
      "\n",
      "{'Hamming Loss': 0.04673913043478261, 'Macro F1': 0.006746626686656672, 'Micro F1': 0.17307692307692304, 'Subset Accuracy': 0.0}\n"
     ]
    }
   ],
   "source": [
    "def get_predictions(model, data_loader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs = {key: val.squeeze(1).to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.sigmoid(logits)  \n",
    "            preds = (probs > threshold).int() \n",
    "            \n",
    "            all_predictions.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_predictions.numpy(), all_labels.numpy()\n",
    "\n",
    "def evaluate_model(model, data_loader, device, val_data, class_labels, print_report=True):\n",
    "    y_pred, y_true = get_predictions(model, data_loader, device)\n",
    "\n",
    "    hamming = hamming_loss(y_true, y_pred)\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    micro_f1 = f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "    subset_accuracy = (y_true == y_pred).all(axis=1).mean()\n",
    "\n",
    "    if print_report:\n",
    "        report = classification_report(\n",
    "            y_true, y_pred, target_names=class_labels, digits=2, zero_division=0\n",
    "        )\n",
    "        print(\"\\nClassification Report:\\n\")\n",
    "        print(report)\n",
    "\n",
    "    return {\"Hamming Loss\": hamming, \"Macro F1\": macro_f1, \"Micro F1\": micro_f1, \"Subset Accuracy\": subset_accuracy}\n",
    "\n",
    "print(\"Evaluating on Validation Set...\")\n",
    "evaluation_results = evaluate_model(model, val_loader, device, val_data, all_narratives + all_subnarratives)\n",
    "print(evaluation_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
