{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import tqdm\n",
    "import zipfile\n",
    "from conllu import parse\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import hamming_loss, f1_score, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep existing constants and data loading code...\n",
    "TARGET_LANG = ['EN', 'BG', 'PT', 'RU']\n",
    "RAW_DATASET_PATH = '../data/raw/target_4_December_release'\n",
    "PREPROCESSED_DATASET_PATH = '../data/preprocessed/preprocessed_target_4_December_release'\n",
    "LABELS_PATH = [os.path.join(RAW_DATASET_PATH, lang, 'subtask-2-annotations.txt') for lang in TARGET_LANG]\n",
    "INPUTS_PATH = [os.path.join(PREPROCESSED_DATASET_PATH, lang) for lang in TARGET_LANG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified Dataset class to handle separate narrative and subnarrative tasks\n",
    "class NarrativeDataset(Dataset):\n",
    "    def __init__(self, articles, tokenizer, max_len, task_type='narrative'):\n",
    "        self.articles = articles\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.task_type = task_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.articles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        article = self.articles.iloc[idx]\n",
    "        inputs = self.tokenizer(\n",
    "            article[\"text\"],\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Select appropriate labels based on task\n",
    "        if self.task_type == 'narrative':\n",
    "            labels = article[\"narrative_labels\"]\n",
    "        else:\n",
    "            labels = article[\"subnarrative_labels\"]\n",
    "            \n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.float32)\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract datasets if needed\n",
    "def extract_datasets():\n",
    "    if not os.path.exists(RAW_DATASET_PATH):\n",
    "        with zipfile.ZipFile(RAW_DATASET_PATH + '.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall(RAW_DATASET_PATH, pwd=b'narratives5202trainTHREE')\n",
    "    \n",
    "    if not os.path.exists(PREPROCESSED_DATASET_PATH):\n",
    "        with zipfile.ZipFile(PREPROCESSED_DATASET_PATH + '.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall(PREPROCESSED_DATASET_PATH)\n",
    "\n",
    "def load_and_map_labels(label_file_paths: list[str]):\n",
    "    \"\"\"Load and map narrative labels from files.\"\"\"\n",
    "    all_labels = []\n",
    "    all_narratives_set = set()\n",
    "    all_subnarratives_set = set()\n",
    "    \n",
    "    for label_file_path in label_file_paths:\n",
    "        labels_df = pd.read_csv(\n",
    "            label_file_path, \n",
    "            sep=\"\\t\", \n",
    "            header=None, \n",
    "            names=[\"article_id\", \"narratives\", \"subnarratives\"]\n",
    "        )\n",
    "        \n",
    "        for _, row in labels_df.iterrows():\n",
    "            # Extract narratives and subnarratives\n",
    "            narratives = row[\"narratives\"].split(\";\") if pd.notna(row[\"narratives\"]) else []\n",
    "            subnarratives = row[\"subnarratives\"].split(\";\") if pd.notna(row[\"subnarratives\"]) else []\n",
    "            \n",
    "            # Update sets of unique labels\n",
    "            all_narratives_set.update(narratives)\n",
    "            all_subnarratives_set.update(subnarratives)\n",
    "            \n",
    "            all_labels.append({\n",
    "                \"article_id\": row[\"article_id\"],\n",
    "                \"narratives\": narratives,\n",
    "                \"subnarratives\": subnarratives\n",
    "            })\n",
    "    \n",
    "    # Convert sets to sorted lists for consistent ordering\n",
    "    all_narratives = sorted(list(all_narratives_set - {''} if '' in all_narratives_set else all_narratives_set))\n",
    "    all_subnarratives = sorted(list(all_subnarratives_set - {''} if '' in all_subnarratives_set else all_subnarratives_set))\n",
    "    \n",
    "    return pd.DataFrame(all_labels), all_narratives, all_subnarratives\n",
    "\n",
    "def parse_conllu_file(file_path):\n",
    "    \"\"\"Parse a CoNLL-U format file and return concatenated tokens.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "    token_lists = parse(data)\n",
    "    all_tokens = [token[\"form\"] for token_list in token_lists for token in token_list]\n",
    "    return \" \".join(all_tokens)\n",
    "\n",
    "def map_input_to_label(articles_paths: list[str], article_ids: list[str], labels: pd.DataFrame):\n",
    "    \"\"\"Map input articles to their corresponding labels.\"\"\"\n",
    "    labels = labels.set_index(\"article_id\")\n",
    "    \n",
    "    articles_data = []\n",
    "    for articles_path in articles_paths:\n",
    "        for article_id in article_ids:\n",
    "            file_path = os.path.join(articles_path, f\"{article_id.replace('.txt', '.conllu')}\")\n",
    "            if os.path.exists(file_path) and article_id in labels.index:\n",
    "                article_text = parse_conllu_file(file_path)\n",
    "                article_labels = labels.loc[article_id]\n",
    "                articles_data.append({\n",
    "                    \"article_id\": article_id,\n",
    "                    \"text\": article_text,\n",
    "                    \"narratives\": article_labels[\"narratives\"],\n",
    "                    \"subnarratives\": article_labels[\"subnarratives\"]\n",
    "                })\n",
    "    return pd.DataFrame(articles_data)\n",
    "\n",
    "class NarrativeDataset(Dataset):\n",
    "    def __init__(self, articles, tokenizer, max_len, task_type='narrative'):\n",
    "        self.articles = articles\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.task_type = task_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.articles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        article = self.articles.iloc[idx]\n",
    "        inputs = self.tokenizer(\n",
    "            article[\"text\"],\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        if self.task_type == 'narrative':\n",
    "            labels = article[\"narrative_labels\"]\n",
    "        else:\n",
    "            labels = article[\"subnarrative_labels\"]\n",
    "            \n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "def get_predictions(model, data_loader, device, threshold=0.3):\n",
    "    \"\"\"Generate predictions from the model.\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > threshold).int()\n",
    "            \n",
    "            all_predictions.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    return torch.cat(all_predictions, dim=0).numpy(), torch.cat(all_labels, dim=0).numpy()\n",
    "\n",
    "def evaluate_model(y_pred, y_true, class_labels, print_report=False):\n",
    "    \"\"\"Evaluate model performance using multiple metrics.\"\"\"\n",
    "    hamming = hamming_loss(y_true, y_pred)\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    micro_f1 = f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "    subset_accuracy = (y_true == y_pred).all(axis=1).mean()\n",
    "\n",
    "    if print_report:\n",
    "        report = classification_report(\n",
    "            y_true, y_pred, target_names=class_labels, digits=2, zero_division=0\n",
    "        )\n",
    "        print(\"\\nClassification Report:\\n\")\n",
    "        print(report)\n",
    "\n",
    "    return {\n",
    "        \"Hamming Loss\": hamming,\n",
    "        \"Macro F1\": macro_f1,\n",
    "        \"Micro F1\": micro_f1,\n",
    "        \"Subset Accuracy\": subset_accuracy\n",
    "    }\n",
    "\n",
    "def create_weighted_sampler(labels):\n",
    "    \"\"\"Create a weighted sampler to handle class imbalance.\"\"\"\n",
    "    label_counts = np.sum(labels, axis=0)\n",
    "    weights = 1.0 / label_counts\n",
    "    weights = np.nan_to_num(weights, nan=1.0, posinf=1.0)\n",
    "    sample_weights = np.sum(labels * weights, axis=1)\n",
    "    return WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "\n",
    "def prepare_data(df, all_narratives, all_subnarratives):\n",
    "    \"\"\"Prepare separate datasets for narratives and subnarratives.\"\"\"\n",
    "    narrative_labels = df[\"narratives\"].apply(\n",
    "        lambda x: [1 if n in x else 0 for n in all_narratives]\n",
    "    ).tolist()\n",
    "    \n",
    "    subnarrative_labels = df[\"subnarratives\"].apply(\n",
    "        lambda x: [1 if sn in x else 0 for sn in all_subnarratives]\n",
    "    ).tolist()\n",
    "    \n",
    "    df[\"narrative_labels\"] = narrative_labels\n",
    "    df[\"subnarrative_labels\"] = subnarrative_labels\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, task_type, all_narratives, all_subnarratives, num_epochs=3):\n",
    "    \"\"\"Training function with improved logging and early stopping.\n",
    "    \n",
    "    Args:\n",
    "        model: The BERT model to train\n",
    "        train_loader: DataLoader for training data\n",
    "        val_loader: DataLoader for validation data\n",
    "        device: torch device (cuda or cpu)\n",
    "        task_type: Either 'narrative' or 'subnarrative'\n",
    "        all_narratives: List of all unique narrative labels\n",
    "        all_subnarratives: List of all unique subnarrative labels\n",
    "        num_epochs: Number of training epochs\n",
    "    \"\"\"\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    best_f1 = 0\n",
    "    patience = 3\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs} - {task_type.capitalize()} Classification\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        progress_bar = tqdm.tqdm(train_loader, desc=\"Training\")\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "        \n",
    "        y_pred, y_true = get_predictions(model, val_loader, device, threshold=0.3)\n",
    "        class_labels = all_narratives if task_type == 'narrative' else all_subnarratives\n",
    "        val_metrics = evaluate_model(\n",
    "            y_pred, \n",
    "            y_true, \n",
    "            class_labels,\n",
    "            print_report=True\n",
    "        )\n",
    "        \n",
    "        print(f\"Validation Metrics:\")\n",
    "        for metric, value in val_metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        \n",
    "        current_f1 = val_metrics['Macro F1']\n",
    "        if current_f1 > best_f1:\n",
    "            best_f1 = current_f1\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f'best_{task_type}_model.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after epoch {epoch + 1}\")\n",
    "                break\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 unique narratives and 94 unique subnarratives\n",
      "\n",
      "Narratives: ['CC: Amplifying Climate Fears', 'CC: Climate change is beneficial', 'CC: Controversy about green technologies', 'CC: Criticism of climate movement', 'CC: Criticism of climate policies', 'CC: Criticism of institutions and authorities', 'CC: Downplaying climate change', 'CC: Green policies are geopolitical instruments', 'CC: Hidden plots by secret schemes of powerful groups', 'CC: Questioning the measurements and science', 'Other', 'URW: Amplifying war-related fears', 'URW: Blaming the war on others rather than the invader', 'URW: Discrediting Ukraine', 'URW: Discrediting the West, Diplomacy', 'URW: Distrust towards Media', 'URW: Hidden plots by secret schemes of powerful groups', 'URW: Negative Consequences for the West', 'URW: Overpraising the West', 'URW: Praise of Russia', 'URW: Russia is the Victim', 'URW: Speculating war outcomes']\n",
      "\n",
      "Subnarratives: ['CC: Amplifying Climate Fears: Amplifying existing fears of global warming', 'CC: Amplifying Climate Fears: Doomsday scenarios for humans', 'CC: Amplifying Climate Fears: Earth will be uninhabitable soon', 'CC: Amplifying Climate Fears: Other', 'CC: Amplifying Climate Fears: Whatever we do it is already too late', 'CC: Climate change is beneficial: CO2 is beneficial', 'CC: Climate change is beneficial: Other', 'CC: Climate change is beneficial: Temperature increase is beneficial', 'CC: Controversy about green technologies: Other', 'CC: Controversy about green technologies: Renewable energy is costly', 'CC: Controversy about green technologies: Renewable energy is dangerous', 'CC: Controversy about green technologies: Renewable energy is unreliable', 'CC: Criticism of climate movement: Ad hominem attacks on key activists', 'CC: Criticism of climate movement: Climate movement is alarmist', 'CC: Criticism of climate movement: Climate movement is corrupt', 'CC: Criticism of climate movement: Other', 'CC: Criticism of climate policies: Climate policies are ineffective', 'CC: Criticism of climate policies: Climate policies are only for profit', 'CC: Criticism of climate policies: Climate policies have negative impact on the economy', 'CC: Criticism of climate policies: Other', 'CC: Criticism of institutions and authorities: Criticism of international entities', 'CC: Criticism of institutions and authorities: Criticism of national governments', 'CC: Criticism of institutions and authorities: Criticism of political organizations and figures', 'CC: Criticism of institutions and authorities: Criticism of the EU', 'CC: Criticism of institutions and authorities: Other', 'CC: Downplaying climate change: CO2 concentrations are too small to have an impact', 'CC: Downplaying climate change: Climate cycles are natural', 'CC: Downplaying climate change: Human activities do not impact climate change', 'CC: Downplaying climate change: Humans and nature will adapt to the changes', 'CC: Downplaying climate change: Ice is not melting', 'CC: Downplaying climate change: Other', 'CC: Downplaying climate change: Sea levels are not rising', 'CC: Downplaying climate change: Temperature increase does not have significant impact', 'CC: Downplaying climate change: Weather suggests the trend is global cooling', 'CC: Green policies are geopolitical instruments: Climate-related international relations are abusive/exploitative', 'CC: Green policies are geopolitical instruments: Green activities are a form of neo-colonialism', 'CC: Green policies are geopolitical instruments: Other', 'CC: Hidden plots by secret schemes of powerful groups: Blaming global elites', 'CC: Hidden plots by secret schemes of powerful groups: Climate agenda has hidden motives', 'CC: Hidden plots by secret schemes of powerful groups: Other', 'CC: Questioning the measurements and science: Data shows no temperature increase', 'CC: Questioning the measurements and science: Greenhouse effect/carbon dioxide do not drive climate change', 'CC: Questioning the measurements and science: Methodologies/metrics used are unreliable/faulty', 'CC: Questioning the measurements and science: Other', 'CC: Questioning the measurements and science: Scientific community is unreliable', 'Other', 'URW: Amplifying war-related fears: By continuing the war we risk WWIII', 'URW: Amplifying war-related fears: NATO should/will directly intervene', 'URW: Amplifying war-related fears: Other', 'URW: Amplifying war-related fears: Russia will also attack other countries', 'URW: Amplifying war-related fears: There is a real possibility that nuclear weapons will be employed', 'URW: Blaming the war on others rather than the invader: Other', 'URW: Blaming the war on others rather than the invader: The West are the aggressors', 'URW: Blaming the war on others rather than the invader: Ukraine is the aggressor', 'URW: Discrediting Ukraine: Discrediting Ukrainian government and officials and policies', 'URW: Discrediting Ukraine: Discrediting Ukrainian military', 'URW: Discrediting Ukraine: Discrediting Ukrainian nation and society', 'URW: Discrediting Ukraine: Other', 'URW: Discrediting Ukraine: Rewriting Ukraine’s history', 'URW: Discrediting Ukraine: Situation in Ukraine is hopeless', 'URW: Discrediting Ukraine: Ukraine is a hub for criminal activities', 'URW: Discrediting Ukraine: Ukraine is a puppet of the West', 'URW: Discrediting Ukraine: Ukraine is associated with nazism', 'URW: Discrediting the West, Diplomacy: Diplomacy does/will not work', 'URW: Discrediting the West, Diplomacy: Other', 'URW: Discrediting the West, Diplomacy: The EU is divided', 'URW: Discrediting the West, Diplomacy: The West does not care about Ukraine, only about its interests', 'URW: Discrediting the West, Diplomacy: The West is overreacting', 'URW: Discrediting the West, Diplomacy: The West is weak', 'URW: Discrediting the West, Diplomacy: West is tired of Ukraine', 'URW: Distrust towards Media: Other', 'URW: Distrust towards Media: Ukrainian media cannot be trusted', 'URW: Distrust towards Media: Western media is an instrument of propaganda', 'URW: Hidden plots by secret schemes of powerful groups: Other', 'URW: Negative Consequences for the West: Other', 'URW: Negative Consequences for the West: Sanctions imposed by Western countries will backfire', 'URW: Negative Consequences for the West: The conflict will increase the Ukrainian refugee flows to Europe', 'URW: Overpraising the West: NATO will destroy Russia', 'URW: Overpraising the West: Other', 'URW: Overpraising the West: The West belongs in the right side of history', 'URW: Overpraising the West: The West has the strongest international support', 'URW: Praise of Russia: Other', 'URW: Praise of Russia: Praise of Russian President Vladimir Putin', 'URW: Praise of Russia: Praise of Russian military might', 'URW: Praise of Russia: Russia has international support from a number of countries and people', 'URW: Praise of Russia: Russia is a guarantor of peace and prosperity', 'URW: Praise of Russia: Russian invasion has strong national support', 'URW: Russia is the Victim: Other', 'URW: Russia is the Victim: Russia actions in Ukraine are only self-defence', 'URW: Russia is the Victim: The West is russophobic', 'URW: Russia is the Victim: UA is anti-RU extremists', 'URW: Speculating war outcomes: Other', 'URW: Speculating war outcomes: Russian army is collapsing', 'URW: Speculating war outcomes: Ukrainian army is collapsing']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_148981/2007617684.py:149: RuntimeWarning: divide by zero encountered in divide\n",
      "  weights = 1.0 / label_counts\n",
      "/home/theo/.pyenv/versions/3.12.7/envs/nlp/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Narrative Model...\n",
      "\n",
      "Epoch 1/3 - Narrative Classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 1/40 [00:25<16:31, 25.43s/it, Loss=0.7075]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 76\u001b[0m\n\u001b[1;32m     70\u001b[0m subnarrative_model \u001b[38;5;241m=\u001b[39m BertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-multilingual-cased\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     72\u001b[0m     num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(all_subnarratives)\n\u001b[1;32m     73\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Narrative Model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m narrative_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnarrative_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_narrative_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_narrative_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnarrative\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_narratives\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_subnarratives\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining Subnarrative Model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m subnarrative_model \u001b[38;5;241m=\u001b[39m train_model(\n\u001b[1;32m     88\u001b[0m     subnarrative_model,\n\u001b[1;32m     89\u001b[0m     train_subnarrative_loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m     all_subnarratives\n\u001b[1;32m     95\u001b[0m )\n",
      "Cell \u001b[0;32mIn[7], line 204\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, device, task_type, all_narratives, all_subnarratives, num_epochs)\u001b[0m\n\u001b[1;32m    201\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m    202\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m--> 204\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m    206\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/envs/nlp/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/envs/nlp/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/envs/nlp/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Extract datasets\n",
    "    extract_datasets()\n",
    "    \n",
    "    # Load labels and get unique narratives and subnarratives\n",
    "    labels_df, all_narratives, all_subnarratives = load_and_map_labels(LABELS_PATH)\n",
    "    \n",
    "    print(f\"Found {len(all_narratives)} unique narratives and {len(all_subnarratives)} unique subnarratives\")\n",
    "    print(\"\\nNarratives:\", all_narratives)\n",
    "    print(\"\\nSubnarratives:\", all_subnarratives)\n",
    "    \n",
    "    # Map inputs to labels\n",
    "    article_ids = labels_df[\"article_id\"]\n",
    "    df = map_input_to_label(INPUTS_PATH, article_ids, labels_df)\n",
    "    \n",
    "    # Remove excess \"Other\" labels\n",
    "    other_df = df[\n",
    "        df[\"narratives\"].apply(lambda x: any(\"Other\" in item for item in x)) & \n",
    "        df[\"subnarratives\"].apply(lambda x: any(\"Other\" in item for item in x))\n",
    "    ].sample(frac=0.7, random_state=42)\n",
    "    df = df.drop(other_df.index)\n",
    "    \n",
    "    # Prepare data\n",
    "    df = prepare_data(df, all_narratives, all_subnarratives)\n",
    "    \n",
    "    # Split data\n",
    "    train_data, val_data = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"narratives\"].apply(len))\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "    \n",
    "    # Create datasets for both tasks\n",
    "    train_narrative_dataset = NarrativeDataset(train_data, tokenizer, max_len=512, task_type='narrative')\n",
    "    val_narrative_dataset = NarrativeDataset(val_data, tokenizer, max_len=512, task_type='narrative')\n",
    "    \n",
    "    train_subnarrative_dataset = NarrativeDataset(train_data, tokenizer, max_len=512, task_type='subnarrative')\n",
    "    val_subnarrative_dataset = NarrativeDataset(val_data, tokenizer, max_len=512, task_type='subnarrative')\n",
    "    \n",
    "    # Create weighted samplers\n",
    "    narrative_sampler = create_weighted_sampler(train_data[\"narrative_labels\"].tolist())\n",
    "    subnarrative_sampler = create_weighted_sampler(train_data[\"subnarrative_labels\"].tolist())\n",
    "    \n",
    "    # Create data loaders with weighted sampling\n",
    "    train_narrative_loader = DataLoader(\n",
    "        train_narrative_dataset, \n",
    "        batch_size=16,  # Reduced batch size\n",
    "        sampler=narrative_sampler,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    train_subnarrative_loader = DataLoader(\n",
    "        train_subnarrative_dataset,\n",
    "        batch_size=16,\n",
    "        sampler=subnarrative_sampler,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_narrative_loader = DataLoader(val_narrative_dataset, batch_size=16, shuffle=False)\n",
    "    val_subnarrative_loader = DataLoader(val_subnarrative_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    # Initialize models\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    narrative_model = BertForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-multilingual-cased\",\n",
    "        num_labels=len(all_narratives)\n",
    "    ).to(device)\n",
    "    \n",
    "    subnarrative_model = BertForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-multilingual-cased\",\n",
    "        num_labels=len(all_subnarratives)\n",
    "    ).to(device)\n",
    "    \n",
    "    print(\"Training Narrative Model...\")\n",
    "    narrative_model = train_model(\n",
    "        narrative_model,\n",
    "        train_narrative_loader,\n",
    "        val_narrative_loader,\n",
    "        device,\n",
    "        'narrative',\n",
    "        all_narratives,\n",
    "        all_subnarratives\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining Subnarrative Model...\")\n",
    "    subnarrative_model = train_model(\n",
    "        subnarrative_model,\n",
    "        train_subnarrative_loader,\n",
    "        val_subnarrative_loader,\n",
    "        device,\n",
    "        'subnarrative',\n",
    "        all_narratives,\n",
    "        all_subnarratives\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
